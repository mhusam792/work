# import streamlit as st
# import cv2
# from PIL import Image
# import numpy as np
# from streamlit_extras.image_selector import image_selector
# from paddleocr import PaddleOCR

# ocr = PaddleOCR(use_angle_cls=True, lang='en')

# st.set_page_config(layout="wide")
# st.title("ğŸ“ Ù†Ø¸Ø§Ù… ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…Ù† ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø©")

# uploaded_image = st.file_uploader("ğŸ“· Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ø§Ù„Ù…Ø®Ø·Ø· Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠ", type=["jpg", "png", "jpeg"])

# # ğŸ¨ Ø£Ù„ÙˆØ§Ù† Ù…Ø®ØªÙ„ÙØ© Ù„ÙƒÙ„ Ø¹Ù…ÙˆØ¯
# colors = [
#     (255, 0, 0),      # Ø£Ø­Ù…Ø±
#     (0, 255, 0),      # Ø£Ø®Ø¶Ø±
#     (0, 0, 255),      # Ø£Ø²Ø±Ù‚
#     (255, 255, 0),    # Ø£ØµÙØ±
#     (255, 0, 255),    # Ø¨Ù†ÙØ³Ø¬ÙŠ
#     (0, 255, 255),    # Ø³Ù…Ø§ÙˆÙŠ
#     (128, 0, 128)     # Ø¨Ù†ÙØ³Ø¬ÙŠ ØºØ§Ù…Ù‚
# ]

# def draw_all_boxes(image_np, boxes):
#     for idx, box in enumerate(boxes):
#         color = colors[idx % len(colors)]
#         cv2.rectangle(
#             image_np,
#             (box['x_min'], box['y_min']),
#             (box['x_max'], box['y_max']),
#             color=color,
#             thickness=3
#         )
#     return image_np

# def get_box_coords(selection):
#     try:
#         if selection and selection.get("selection") and "box" in selection["selection"]:
#             boxes = selection["selection"]["box"]
#             if boxes:
#                 box = boxes[0]
#                 x_vals = box["x"]
#                 y_vals = box["y"]
#                 return {
#                     'x_min': int(min(x_vals)),
#                     'x_max': int(max(x_vals)),
#                     'y_min': int(min(y_vals)),
#                     'y_max': int(max(y_vals)),
#                 }
#     except Exception as e:
#         st.error(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª: {e}")
#     return None


# def extract_cells_with_gaps(ocr_result, max_rows, gap_threshold=25):
#     """
#     ocr_result: Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù€ OCR (Ù…Ù† ocr.predict)
#     max_rows: Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©
#     gap_threshold: Ø§Ù„Ù…Ø³Ø§ÙØ© Ø¨ÙŠÙ† ÙƒÙ„ Ø³Ø·Ø± ÙˆØ§Ù„ØªØ§Ù†ÙŠ Ù„ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø®Ù„Ø§ÙŠØ§ Ø§Ù„ÙØ§Ø¶ÙŠØ©
#     """
#     texts = ocr_result[0]['rec_texts']
#     boxes = ocr_result[0]['rec_boxes']

#     lines_with_y = []
#     for text, box in zip(texts, boxes):
#         # ØªØ£ÙƒØ¯ Ø¥Ù† box ÙÙŠÙ‡ 4 Ù†Ù‚Ø§Ø· ÙˆÙƒÙ„ Ù†Ù‚Ø·Ø© ÙÙŠÙ‡Ø§ x,y
#         try:
#             if isinstance(box, (list, np.ndarray)) and len(box) == 4:
#                 y_center = (box[0][1] + box[2][1]) / 2
#                 lines_with_y.append((text, y_center))
#         except Exception as e:
#             continue  # Ù„Ùˆ Ø­ØµÙ„ Ø£ÙŠ Ø®Ø·Ø£ ÙÙŠ boxØŒ ØªØ¬Ø§Ù‡Ù„Ù‡

#     # Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø±Ø£Ø³ÙŠ Ù…Ù† Ø£Ø¹Ù„Ù‰ Ù„Ø£Ø³ÙÙ„
#     lines_with_y.sort(key=lambda x: x[1])

#     rows = []
#     prev_y = None
#     for text, y in lines_with_y:
#         if prev_y is not None and abs(y - prev_y) > gap_threshold:
#             rows.append(None)  # ØµÙ ÙØ§Ø¶ÙŠ
#         rows.append(text.strip())
#         prev_y = y

#     # Ø§Ø³ØªÙƒÙ…Ø§Ù„ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù†Ø§Ù‚ØµØ©
#     while len(rows) < max_rows:
#         rows.append(None)

#     return rows[:max_rows]
# # ------------------------------
# # ğŸš€ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
# # ------------------------------
# if uploaded_image is not None:
#     image_pil = Image.open(uploaded_image).convert("RGB")
#     image_np_original = np.array(image_pil)
#     image_np_display = image_np_original.copy()

#     # Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
#     if "all_boxes" not in st.session_state:
#         st.session_state.all_boxes = []
#         st.session_state.selected_regions = []
#         st.session_state.column_index = 0

#     if st.session_state.column_index < 7:
#         st.markdown(f"### âœ‚ï¸ Ø­Ø¯Ø¯ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø±Ù‚Ù… {st.session_state.column_index + 1}")
#         image_np_with_boxes = draw_all_boxes(image_np_display.copy(), st.session_state.all_boxes)
#         image_with_boxes_pil = Image.fromarray(image_np_with_boxes)

#         # Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ÙˆØ­ÙŠØ¯Ø© Ø§Ù„ØªÙŠ ÙŠØ­Ø¯Ø¯ Ù…Ù†Ù‡Ø§ ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
#         selection = image_selector(image_with_boxes_pil, key=f"selector_{st.session_state.column_index}")
#         box_coords = get_box_coords(selection)

#         if box_coords:
#             st.session_state.all_boxes.append(box_coords)

#             # Ù‚Øµ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù…Ø­Ø¯Ø¯
#             x_min, x_max = box_coords['x_min'], box_coords['x_max']
#             y_min, y_max = box_coords['y_min'], box_coords['y_max']
#             cropped_np = image_np_original[y_min:y_max, x_min:x_max]
#             cropped_pil = Image.fromarray(cropped_np)
#             st.session_state.selected_regions.append(cropped_pil)

#             st.session_state.column_index += 1
#             st.rerun()  # ğŸ” ÙŠØ¹ÙŠØ¯ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø© Ø¨ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ§Ù„ÙŠ
#         else:
#             st.image(image_with_boxes_pil, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©", use_container_width=True)
#     else:
#         st.success("âœ… ØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø³Ø¨Ø¹Ø© Ø¨Ù†Ø¬Ø§Ø­!")

#         # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¨ÙƒÙ„ Ø§Ù„ØªØ­Ø¯ÙŠØ¯Ø§Øª
#         final_image_np = draw_all_boxes(image_np_original.copy(), st.session_state.all_boxes)
#         st.image(final_image_np, caption="ğŸ“Œ ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø³Ø¨Ø¹Ø©", use_container_width=True)

#         # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ
#         for idx, region in enumerate(st.session_state.selected_regions):
#             st.markdown(f"### ğŸ“ Ø§Ù„Ø¹Ù…ÙˆØ¯ {idx + 1}")
#             st.image(region, caption=f"ğŸ“¸ Ø§Ù„Ø¬Ø²Ø¡ {idx + 1}", use_container_width=True)

#             img_bgr = cv2.cvtColor(np.array(region), cv2.COLOR_RGB2BGR)
#             result = ocr.predict(img_bgr)

#             # Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ (ÙŠØ¯Ø®Ù„Ù‡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…)
#             num_rows = st.number_input(f"ğŸ§® ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ ÙÙŠ Ø§Ù„Ø¹Ù…ÙˆØ¯ {idx + 1}ØŸ", min_value=1, max_value=100, step=1, key=f"rows_{idx}")

#             # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ ÙˆØªÙ‚Ø¯ÙŠØ± Ø§Ù„ØµÙÙˆÙ
#             cells = extract_cells_with_gaps(result, num_rows)

#             # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø©
#             st.markdown("### ğŸ—‚ï¸ Ù…Ø­ØªÙˆÙŠØ§Øª Ø§Ù„Ø¹Ù…ÙˆØ¯ Ù…Ø¹ ØµÙÙˆÙ ÙØ§Ø±ØºØ©:")
#             for i, cell in enumerate(cells, 1):
#                 display = cell if cell else "âŒ null"
#                 st.write(f"ØµÙ {i}: {display}")


#         # Ø²Ø± Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ­Ø¯ÙŠØ¯
#         if st.button("ğŸ”„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ­Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©"):
#             st.session_state.all_boxes = []
#             st.session_state.selected_regions = []
#             st.session_state.column_index = 0
#             st.rerun()


# 

import streamlit as st
import cv2
from PIL import Image
import numpy as np
from streamlit_extras.image_selector import image_selector

st.set_page_config(layout="wide")
st.title("ğŸ“ Ù†Ø¸Ø§Ù… ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ§Ù„Ø®Ù„ÙŠØ© Ù…Ù† ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø©")

uploaded_image = st.file_uploader("ğŸ“· Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ø§Ù„Ù…Ø®Ø·Ø· Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠ", type=["jpg", "png", "jpeg"])

colors = [
    (255, 0, 0), (0, 255, 0), (0, 0, 255),
    (255, 255, 0), (255, 0, 255), (0, 255, 255),
    (128, 0, 128)
]

def draw_all_boxes(image_np, boxes, extra_box=None):
    for idx, box in enumerate(boxes):
        color = colors[idx % len(colors)]
        cv2.rectangle(
            image_np,
            (box['x_min'], box['y_min']),
            (box['x_max'], box['y_max']),
            color=color,
            thickness=3
        )
    if extra_box:
        cv2.rectangle(
            image_np,
            (extra_box['x_min'], extra_box['y_min']),
            (extra_box['x_max'], extra_box['y_max']),
            (0, 0, 0),  # Ø£Ø³ÙˆØ¯
            thickness=3
        )
    return image_np

def get_box_coords(selection):
    try:
        if selection and selection.get("selection") and "box" in selection["selection"]:
            boxes = selection["selection"]["box"]
            if boxes:
                box = boxes[0]
                x_vals = box["x"]
                y_vals = box["y"]
                return {
                    'x_min': int(min(x_vals)),
                    'x_max': int(max(x_vals)),
                    'y_min': int(min(y_vals)),
                    'y_max': int(max(y_vals)),
                }
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª: {e}")
    return None

if uploaded_image is not None:
    image_pil = Image.open(uploaded_image).convert("RGB")
    image_np_original = np.array(image_pil)
    image_np_display = image_np_original.copy()

    # Ø­Ø§Ù„Ø© Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
    if "all_boxes" not in st.session_state:
        st.session_state.all_boxes = []
        st.session_state.column_index = 0
        st.session_state.cell_box = None
        st.session_state.step = "columns"

    if st.session_state.step == "columns":
        if st.session_state.column_index < 7:
            st.markdown(f"### âœ‚ï¸ Ø­Ø¯Ø¯ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø±Ù‚Ù… {st.session_state.column_index + 1}")

            image_with_boxes = draw_all_boxes(image_np_display.copy(), st.session_state.all_boxes)
            image_with_boxes_pil = Image.fromarray(image_with_boxes)

            selection = image_selector(image_with_boxes_pil, key=f"selector_col_{st.session_state.column_index}")
            box = get_box_coords(selection)

            if box:
                st.session_state.all_boxes.append(box)
                st.session_state.column_index += 1
                st.rerun()
            else:
                st.image(image_with_boxes_pil, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©", use_container_width=True)
        else:
            st.session_state.step = "cell"
            st.rerun()

    elif st.session_state.step == "cell":
        st.markdown("### ğŸŸ© Ø­Ø¯Ø¯ Ø®Ù„ÙŠØ© ÙˆØ§Ø­Ø¯Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„ØµÙˆØ±Ø© (Ø§Ù„Ù…Ø±Ø¨Ø¹ Ø§Ù„ØªØ§Ù…Ù†)")
        image_with_boxes = draw_all_boxes(image_np_display.copy(), st.session_state.all_boxes)
        image_with_boxes_pil = Image.fromarray(image_with_boxes)
        selection = image_selector(image_with_boxes_pil, key="selector_cell")

        box = get_box_coords(selection)
        if box:
            st.session_state.cell_box = box
            st.session_state.step = "done"
            st.rerun()
        else:
            st.image(image_with_boxes_pil, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©", use_container_width=True)

    elif st.session_state.step == "done":
        st.success("âœ… ØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ§Ù„Ø®Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!")
        final_image_np = draw_all_boxes(image_np_original.copy(), st.session_state.all_boxes, st.session_state.cell_box)
        st.image(final_image_np, caption="ğŸ“Œ Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ", use_container_width=True)

        with st.container():
            st.markdown("## ğŸ“‹ Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©")
            for idx, box in enumerate(st.session_state.all_boxes, start=1):
                st.write(f"ğŸ“¦ Ø§Ù„Ø¹Ù…ÙˆØ¯ {idx}: {box}")
            st.write(f"ğŸŸ© Ø§Ù„Ø®Ù„ÙŠØ© (Ø§Ù„Ù…Ø±Ø¨Ø¹ Ø§Ù„ØªØ§Ù…Ù†): {st.session_state.cell_box}")

        if st.button("ğŸ”„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ­Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©"):
            st.session_state.all_boxes = []
            st.session_state.column_index = 0
            st.session_state.cell_box = None
            st.session_state.step = "columns"
            st.rerun()
